{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class ClipEmbeddingsGenerator:\n",
    "    \"\"\"\n",
    "    Class for generating embeddings for images and texts using CLIP model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(self.device)\n",
    "        self.processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "    def embedd_images(self, images_paths: List[str]) -> np.array:\n",
    "        \"\"\"\n",
    "        Embedds images using CLIP model.\n",
    "        :param images_paths: list of paths to images\n",
    "        :return: embeddings of images\n",
    "        \"\"\"\n",
    "        images = [Image.open(path) for path in images_paths]\n",
    "        inputs = self.processor(images=images, return_tensors=\"pt\", text=None).to(self.device)\n",
    "        outputs = self.model.get_image_features(**inputs)\n",
    "        return outputs.cpu().detach().numpy()\n",
    "    \n",
    "    def embedd_texts(self, texts: List[str]) -> np.array:\n",
    "        \"\"\"\n",
    "        Embedds texts using CLIP model.\n",
    "        :param texts: list of image descriptions\n",
    "        :return: embeddings of texts\n",
    "        \"\"\"\n",
    "        inputs = self.processor(images=None, return_tensors=\"pt\", text=texts).to(self.device)\n",
    "        outputs = self.model.get_text_features(**inputs)\n",
    "        return outputs.detach().cpu().numpy()\n",
    "\n",
    "def draw_images(images_paths: List[str], titles: List[str]) -> None:\n",
    "    \"\"\"\n",
    "    Draws images.\n",
    "    :param images_paths: list of paths to images\n",
    "    :param titles: list of titles for images\n",
    "    \"\"\"\n",
    "    images = [mpimg.imread(path) for path in images_paths]\n",
    "\n",
    "    if len(images_paths) == 1:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(images[0])\n",
    "        plt.title(titles[0])\n",
    "        plt.axis(\"off\")\n",
    "    else:    \n",
    "        _, axs = plt.subplots(1, len(images), figsize=(10, 5*len(images)))\n",
    "        for i, (image, title) in enumerate(zip(images, titles)):\n",
    "            axs[i].imshow(image)\n",
    "            axs[i].set_title(title)\n",
    "            axs[i].set_axis_off()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
